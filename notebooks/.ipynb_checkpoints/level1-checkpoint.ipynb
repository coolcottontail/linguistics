{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from math import log10, sqrt\n",
    "from string import punctuation\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Get documents and unique words from docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_words_from_doc(file):\n",
    "    # Extract unique words (unigram, bigram, trigram) from the MASTER DOCUMENT\n",
    "    with open(file, 'r') as f:\n",
    "        all_text = f.read().replace('\\n', ' ')\n",
    "    # Replace single quote (\" ' \") into single white space\n",
    "    allText = all_text.replace(\"'\", \" \")\n",
    "\n",
    "    #set(allText.translate(None, punctuation).lower().split())\n",
    "    return allText.translate(str.maketrans('', '', punctuation)).lower().split()\n",
    "\n",
    "uniqueWords = get_unique_words_from_doc(\"data/combined_docs\")\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_word_without_stopwords(uniqueWords):    \n",
    "    noStopWords = []\n",
    "    for uniqueWord in uniqueWords:\n",
    "        if (not uniqueWord in stopwords):\n",
    "            noStopWords.append(uniqueWord)\n",
    "    return noStopWords\n",
    "uniqueWordList = get_unique_word_without_stopwords(uniqueWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute IDF of unique words in the original files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_original_files = [\"1.txt\",\"2.txt\", \"3.txt\"]\n",
    "\n",
    "def get_df_of_words(uniqueWordList, list_of_original_files):\n",
    "    listofdocs = []                       \n",
    "    for file in list_of_original_files:\n",
    "        listofdocs.append(get_unique_words_from_doc(\"data/\"+file))\n",
    "    dfDict = {}\n",
    "    for uniqueWord in uniqueWordList:\n",
    "        counter = 0\n",
    "        for doc in listofdocs:\n",
    "            if (uniqueWord in doc):\n",
    "                counter += 1\n",
    "        dfDict[uniqueWord] = counter\n",
    "    return dfDict\n",
    "\n",
    "def get_idf_of_words(uniqueWordList, list_of_original_files):\n",
    "    docsize = len(list_of_original_files)\n",
    "    idfDict = get_df_of_words(uniqueWordList, list_of_original_files)\n",
    "    for word in uniqueWordList:\n",
    "        if idfDict[word] == 0:\n",
    "            idfDict[word] = 1\n",
    "        else:\n",
    "            idfDict[word] = 1 + (log10(docsize / idfDict[word]))\n",
    "    return idfDict\n",
    "\n",
    "idfUniqueWordList = get_idf_of_words(uniqueWordList, list_of_original_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute TF of unique words in the original files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_of_word(listofwords, word):\n",
    "    return listofwords.count(word)/len(listofwords)\n",
    "\n",
    "def get_tf_idf_for_file(file, uniqueWordList):\n",
    "    listofwords = get_unique_words_from_doc(\"data/\"+file)\n",
    "    idfDict = get_idf_of_words(uniqueWordList, list_of_original_files)\n",
    "    tfIdfDict = {}\n",
    "    for word in uniqueWordList:\n",
    "        tfIdfDict[word] = get_tf_of_word(listofwords, word) * idfDict[word]\n",
    "    return tfIdfDict\n",
    "\n",
    "idf1 = get_tf_idf_for_file(\"1.txt\", uniqueWordList)\n",
    "idf2 = get_tf_idf_for_file(\"2.txt\", uniqueWordList)\n",
    "idf3 = get_tf_idf_for_file(\"3.txt\", uniqueWordList)\n",
    "idfIn = get_tf_idf_for_file(\"input.txt\", uniqueWordList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get closest document using euclid distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5108047077137732\n",
      "0.441583208778613\n",
      "0.18990590106310087\n"
     ]
    }
   ],
   "source": [
    "def euclid_distance(idf1, idf2, uniqueWordList):\n",
    "    sum = 0\n",
    "    for word in uniqueWordList:\n",
    "        sum += (idf1[word] - idf2[word])*(idf1[word] - idf2[word])\n",
    "    return sqrt(sum)\n",
    "\n",
    "print(euclid_distance(idfIn, idf1, uniqueWordList))\n",
    "print(euclid_distance(idfIn, idf2, uniqueWordList))\n",
    "print(euclid_distance(idfIn, idf3, uniqueWordList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-bdea2f4f3502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midfIn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "idfIn[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
